{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_path = \"data/train.csv\"\n",
    "output_jsonl_path = 5000\n",
    "num_rows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/output_5000.jsonl'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def transform_conversations_to_jsonl(input_csv_path, output_jsonl_path, num_rows=None):\n",
    "    def clean_and_transform_conversation_regex(conversation_str):\n",
    "        \"\"\"\n",
    "        Clean up and transform a single conversation string using regular expressions.\n",
    "        \"\"\"\n",
    "        pattern = r\"\\{'from': '(\\w+)', 'value': \\\"(.*?)\\\"\\}\"\n",
    "        matches = re.findall(pattern, conversation_str, re.DOTALL)\n",
    "        transformed_conversation = []\n",
    "        for match in matches:\n",
    "            from_field, value = match\n",
    "            role = \"user\" if from_field == \"human\" else \"assistant\"\n",
    "            content = value.replace('\\\\\"', '\"').strip()\n",
    "            transformed_conversation.append({\"role\": role, \"content\": content})\n",
    "        return transformed_conversation\n",
    "\n",
    "    df = pd.read_csv(input_csv_path, nrows=num_rows)\n",
    "    \n",
    "    df[\"transformed_conversations\"] = df[\"conversations\"].apply(clean_and_transform_conversation_regex)\n",
    "    \n",
    "    with open(output_jsonl_path, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for _, row in df.iterrows():\n",
    "            output_record = {\"messages\": row[\"transformed_conversations\"]}\n",
    "            json.dump(output_record, jsonl_file)\n",
    "            jsonl_file.write('\\n')  \n",
    "\n",
    "\n",
    "transform_conversations_to_jsonl(input_csv_path, f\"data/output_{num_rows}.jsonl\", num_rows)\n",
    "\n",
    "data_path = f\"data/output_{num_rows}.jsonl\"\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 5000\n",
      "First example:\n",
      "{'role': 'user', 'content': \"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me.\"}\n",
      "{'role': 'assistant', 'content': \"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on?\"}\n",
      "{'role': 'user', 'content': \"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me.\"}\n",
      "{'role': 'assistant', 'content': \"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work?\"}\n",
      "{'role': 'user', 'content': \"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being.\"}\n",
      "{'role': 'assistant', 'content': \"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload?\"}\n",
      "{'role': 'user', 'content': \"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle.\"}\n",
      "{'role': 'assistant', 'content': \"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together.\"}\n",
      "{'role': 'user', 'content': \"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable?\"}\n",
      "{'role': 'assistant', 'content': \"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this.\"}\n",
      "{'role': 'user', 'content': \"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance.\"}\n",
      "{'role': 'assistant', 'content': \"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this!\"}\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found errors:\n",
      "missing_messages_list: 7\n",
      "example_missing_assistant_message: 3\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 5000\n",
      "Num examples missing user message: 10\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 0, 26\n",
      "mean / median: 13.5964, 14.0\n",
      "p5 / p95: 10.0, 17.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 3, 1637\n",
      "mean / median: 744.3164, 737.0\n",
      "p5 / p95: 534.0, 972.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 0, 805\n",
      "mean / median: 359.5268, 357.0\n",
      "p5 / p95: 241.0, 485.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~3721582 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~11164746 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
